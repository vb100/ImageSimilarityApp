{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Image Similarity App.</h2>\n",
    "<h3>Part #1. Feature Extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and packages\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Load the <i>ResNet</i> model without the top classification layer, so we get only the <i>bottleneck features</i>. Then define a function that takes an image path, loads the image, resizes it to proper dimensions supported by <i>ResNet-50</i>, extracts the featues, and then normalizes them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/vytautas/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nDownloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 268s 3us/step\n"
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path, model):\n",
    "    input_shape = (224, 224, 3)\n",
    "    img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalize_features = flattened_features / norm(flattened_features)\n",
    "    return normalize_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Lenght of features for a given sample image is 100352.\n"
    }
   ],
   "source": [
    "# Let's see the feature length that the model generates\n",
    "features = extract_features('./caltech101/ant/image_0020.jpg', model)\n",
    "print('Lenght of features for a given sample image is {}.'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The <i>ResNet-50</i> model generates <i>100352</i> features from the provided image. Each feature is a floating-point value between <code>0</code> and <code>1</code>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We need to extract features for the <b>entire dataset</b>. First, we get all the filenames with a special function, which recursively looksfor all the image files (defined by their extensions) under a directory.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define possible extensions of image files\n",
    "EXTENSIONS = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    counter = 1\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in EXTENSIONS):\n",
    "                file_list.append(os.path.join(root, filename))\n",
    "                counter += 1\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "We found 8677 image files for a given directory (including subcategories).\n"
    }
   ],
   "source": [
    "# Path to the datsets\n",
    "ROOT_DIR = './caltech101'\n",
    "filenames = sorted(get_file_list(ROOT_DIR))\n",
    "print('We found {} image files for a given directory (including subcategories).'.format(len(filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Then we define a variable that will store all of the features, go through all filenames in the dataset, extract their features, and append the to the previously defined variable.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=0, max=8677), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78c590bfdeb8422bac47a951cb8f83d1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(filenames))):\n",
    "    feature_list.append(extract_features(filenames[i], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Finally, write these features to a pickle file so that we can use them in the future without having to recalculate them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(feature_list, open('./data/features-caltech101-resnet.pickle', 'wb'))\n",
    "pickle.dump(filenames, open('./data/filenames-caltech101.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Generated files take a quite huge amout of disk space:\n",
    "<ul>\n",
    "<li><b>File #1.</b> <u>features-caltech101-resnet.pickle</u> - 3.48 GB</li>\n",
    "<li><b>File #2.</b> <u>filenames-caltech101.pickle</u> - 398 KB</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}